20150810161343
/cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS 

Synopsis:	mpirun [options] {-srun | <cmd> | -f <app> }
Description:	Startup an MPI application.
Run styles:

Options (all platforms):
		-help               Print this message.
		-d                  Turn on debugging.
		-version            Print version number.
		-j                  Print the job ID.
		-p                  Pretend to take action.
		-ck                 Pretend to take action, but check host
		                    connectivity and program availability.
		-dbgspin            Application spins in MPI_Init() until user
		                    sets mpi_debug_cont.  See mpidebug(1).
		-v                  Be verbose.
		-i <spec>           Set instrumentation specification.
		-spawn              Include runtime support for spawn.
		-1sided             Include runtime support for 1sided.
		-commd              Route off-host messages via comm daemon.
		-subnet <net-path>  Use subnet associated with hostname
		                    or ip address as returned by
		                    'hostname -i <net-path>'
		-netaddr <ip-designations>
		                    Specifies what IP addresses to use,
		                    like -subnet but with more control
		                    ip-designation is comma separated:
		                    rank:IP[/mask-IP]   - for rank-rank
		                    mpirun:IP[/mask-IP] - for mpirun-*
		                    IP[/mask-IP]        - for both
		-hostlist <quoted-list-of-hosts>
		                    Constructs an appfile using the
		                    specified hosts.  Can be used with
		                    the -np # option.
		-hostfile <filename-of-hosts>
		-machinefile <filename-of-hosts>
		                    Constructs an appfile using the
		                    specified hosts from the file.  Can
		                    be used with the -np # option.
		                    'machinefile' is a synonym for 'hostfile'.
		-lsb_hosts | -lsb_mcpu_hosts
		                    Constructs an appfile using the
		                    LSB_HOSTS or LSB_MCPU_HOSTS env
		                    vars.  Can be used with -np #.
		                    Implies '-lsf' flag
		-lsf
		                    Use 'blaunch' instead of ssh/
		                    Windows Remote Launch service to
		                    launch remote processes.
		-dd|-ndd            Turn on/off deferred memory deregistration
		-TCP                Force to use tcp/ip interconnect
		-srq|-rdma|-xrc|-sndrcv 
		                    -srq: Use short message shared receive
		                    queue(SRQ) protocol if available.
		                    -rdma: Use short message RDMA protocol.
		                    -sndrcv: Use short message Send-Receive 
		                          protocol.
		                    -xrc: Extended Reliable Connection AND -srq
		                    (-xrc not supported by IBM Platform MPI for Windows.
		-intra=shm|nic|mix
		                    Specifies what communication method to
		                    use for intra-host messages.  The default
		                    is shared memory (shm) which should have
		                    the best latency.  The second setting (nic)
		                    causes the same interconnect being used for
		                    inter-host transfers to be used for intra-
		                    host transfers.  On some systems and some
		                    interconnects this might give higher
		                    bandwidth.  The third setting (mix) causes
		                    shared memory to be used for short messages
		                    (below 256K, or MPI_RDMA_INTRALEN if
		                    specified) and the interconnect for longer
		                    messages.
		                    will be the best setting, nic is only
		                    provided for completeness; mix is however
		                    not supported on elan/psm/mx/tcp
		-T                  Print ranks elapsed usr/sys times(2) data.
		-prot               Print ranks communication protocols.
		-cpu_bind[_mt][=arg]   Binds CPUs to ranks for ccNUMA arch.
		-np #               Start '#' processes using 'file'.
		-e <var>[=<val>]    Set env. var. for the processes.
		-sp <paths>         Use <paths> to locate executables.
		-mpi32 | mpi64      Used to indicate application bitness.
		                    This is required for some IBM Platform MPI 
		                    functionality.
		-stdio=<modes>      Set StandardIO modes (See MPI StandardIO
		                    manpage).
		-universe_size=<#>  Set MPI_UNIVERSE_SIZE attribute.

		-f <app>            Use <app> as application file.
		-- [<extra_args>]   Use the remainder of the command line as
		                    extra arguments to each <cmd> in <app>.

		<cmd>               Use <cmd> as SPMD command line.

Options (Linux Only):
		-tv                 Run the application using the TotalView
		                    debugger.
		-ha[:opts]          Turn on High/Availability mode. 
		-prun <options>     Use prun for quadrics support.
		-srun <options>     Use srun for XC support.
		-itapi|-ITAPI       (HP-UX) Causes the ITAPI (IB) protocol
		                    to be used if available.  Upper case option
		                    causes exit if protocol not available
		-hmp|-HMP           (HP-UX) No longer supported.
		-elan|-ELAN         Causes the ELAN protocol (Quadrics)
		                    to be used if available.  Upper case option
		                    causes exit if protocol not available
		-ibv|-IBV           Causes the IBV protocol (OpenFabric)
		                    to be used if available.  Upper case option
		                    causes exit if protocol not available
		-vapi|-VAPI         Causes the VAPI protocol (Mellanox IB)
		                    to be used if available.  Upper case option
		                    causes exit if protocol not available
		-udapl|-UDAPL       Causes the uDAPL protocol (IB + others)
		                    to be used if available.  Upper case option
		                    causes exit if protocol not available
		-gm|-GM             Causes the GM protocol (Myrinet) to be
		                    used if available.  Upper case option
		                    causes exit if protocol not available
		-mx|-MX             Causes the MX protocol (Myrinet) to be
		                    used if available.  Upper case option
		                    causes exit if protocol not available
		-psm|-PSM           Causes the PSM protocol (QLogic) to be
		                    used if available.  Upper case option
		                    causes exit if protocol not available

Application File:	            One per line: [options] <cmd>
		                    Comment lines start with '#'.

Options:	-np,
		-e, -sp             See above.
		<cmd>               Binary program name and arguments.
NOTE: Not all options are supported on all architectures.
IOR-3.0.1: MPI Coordinated Test of Parallel I/O

Began: Mon Aug 10 16:13:45 2015
Command line used: /cosma5/data/dr002/dc-kash1/ior/bin/ior -vvv -b 16g -f /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/con.ior
Machine: Linux m5033
Start time skew across all tasks: 0.00 sec

Test 0 started: Mon Aug 10 16:13:45 2015
Path: /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS
FS: 2435.9 TiB   Used FS: 82.2%   Inodes: 1280.0 Mi   Used Inodes: 5.9%
Participating tasks: 16
Using reorderTasks '-C' (expecting block, not cyclic, task assignment)
Summary:
	api                = MPIIO (version=2, subversion=2)
	test filename      = /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/iorTest
	access             = file-per-process, independent
	pattern            = segmented (1 segment)
	ordering in a file = sequential offsets
	ordering inter file= constant task offsets = 1
	clients            = 16 (1 per node)
	repetitions        = 1
	xfersize           = 4 MiB
	blocksize          = 16 GiB
	aggregate filesize = 256 GiB

access    bw(MiB/s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ---------- ---------  --------   --------   --------   --------   ----
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
write     8804       16777216   4096       0.023131   29.77      2.43       29.77      0   
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
read      4146       16777216   4096       0.028599   63.22      1.04       63.24      0   
remove    -          -          -          -          -          -          0.033957   0   

Max Write: 8804.20 MiB/sec (9231.87 MB/sec)
Max Read:  4145.55 MiB/sec (4346.92 MB/sec)

Summary of all tests:
Operation   Max(MiB)   Min(MiB)  Mean(MiB)     StdDev    Mean(s) Test# #Tasks tPN reps fPP reord reordoff reordrand seed segcnt blksiz xsize aggsize API RefNum
write        8804.20    8804.20    8804.20       0.00   29.77488 0 16 1 1 1 1 1 0 0 1 17179869184 4194304 274877906944 MPIIO 0
read         4145.55    4145.55    4145.55       0.00   63.23507 0 16 1 1 1 1 1 0 0 1 17179869184 4194304 274877906944 MPIIO 0

Finished: Mon Aug 10 16:15:38 2015
IOR-3.0.1: MPI Coordinated Test of Parallel I/O

Began: Mon Aug 10 16:15:39 2015
Command line used: /cosma5/data/dr002/dc-kash1/ior/bin/ior -vvv -b 32g -f /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/con.ior
Machine: Linux m5033
Start time skew across all tasks: 0.00 sec

Test 0 started: Mon Aug 10 16:15:39 2015
Path: /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS
FS: 2435.9 TiB   Used FS: 82.2%   Inodes: 1280.0 Mi   Used Inodes: 5.9%
Participating tasks: 8
Using reorderTasks '-C' (expecting block, not cyclic, task assignment)
Summary:
	api                = MPIIO (version=2, subversion=2)
	test filename      = /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/iorTest
	access             = file-per-process, independent
	pattern            = segmented (1 segment)
	ordering in a file = sequential offsets
	ordering inter file= constant task offsets = 1
	clients            = 8 (1 per node)
	repetitions        = 1
	xfersize           = 4 MiB
	blocksize          = 32 GiB
	aggregate filesize = 256 GiB

access    bw(MiB/s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ---------- ---------  --------   --------   --------   --------   ----
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
write     8415       33554432   4096       0.030221   31.14      3.82       31.15      0   
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
read      4050       33554432   4096       0.022101   64.72      2.43       64.73      0   
remove    -          -          -          -          -          -          0.301890   0   

Max Write: 8415.42 MiB/sec (8824.20 MB/sec)
Max Read:  4050.03 MiB/sec (4246.77 MB/sec)

Summary of all tests:
Operation   Max(MiB)   Min(MiB)  Mean(MiB)     StdDev    Mean(s) Test# #Tasks tPN reps fPP reord reordoff reordrand seed segcnt blksiz xsize aggsize API RefNum
write        8415.42    8415.42    8415.42       0.00   31.15045 0 8 1 1 1 1 1 0 0 1 34359738368 4194304 274877906944 MPIIO 0
read         4050.03    4050.03    4050.03       0.00   64.72636 0 8 1 1 1 1 1 0 0 1 34359738368 4194304 274877906944 MPIIO 0

Finished: Mon Aug 10 16:17:36 2015
IOR-3.0.1: MPI Coordinated Test of Parallel I/O

Began: Mon Aug 10 16:17:39 2015
Command line used: /cosma5/data/dr002/dc-kash1/ior/bin/ior -vvv -b 64g -f /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/con.ior
Machine: Linux m5033
Start time skew across all tasks: 0.00 sec

Test 0 started: Mon Aug 10 16:17:39 2015
Path: /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS
FS: 2435.9 TiB   Used FS: 82.3%   Inodes: 1280.0 Mi   Used Inodes: 5.9%
Participating tasks: 4
Using reorderTasks '-C' (expecting block, not cyclic, task assignment)
Summary:
	api                = MPIIO (version=2, subversion=2)
	test filename      = /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/iorTest
	access             = file-per-process, independent
	pattern            = segmented (1 segment)
	ordering in a file = sequential offsets
	ordering inter file= constant task offsets = 1
	clients            = 4 (1 per node)
	repetitions        = 1
	xfersize           = 4 MiB
	blocksize          = 64 GiB
	aggregate filesize = 256 GiB

access    bw(MiB/s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ---------- ---------  --------   --------   --------   --------   ----
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
write     3873       67108864   4096       0.022731   67.68      29.31      67.69      0   
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
read      3185.65    67108864   4096       0.016643   82.28      0.982673   82.29      0   
remove    -          -          -          -          -          -          0.022328   0   

Max Write: 3872.54 MiB/sec (4060.65 MB/sec)
Max Read:  3185.65 MiB/sec (3340.40 MB/sec)

Summary of all tests:
Operation   Max(MiB)   Min(MiB)  Mean(MiB)     StdDev    Mean(s) Test# #Tasks tPN reps fPP reord reordoff reordrand seed segcnt blksiz xsize aggsize API RefNum
write        3872.54    3872.54    3872.54       0.00   67.69309 0 4 1 1 1 1 1 0 0 1 68719476736 4194304 274877906944 MPIIO 0
read         3185.65    3185.65    3185.65       0.00   82.28895 0 4 1 1 1 1 1 0 0 1 68719476736 4194304 274877906944 MPIIO 0

Finished: Mon Aug 10 16:20:29 2015
IOR-3.0.1: MPI Coordinated Test of Parallel I/O

Began: Mon Aug 10 16:20:31 2015
Command line used: /cosma5/data/dr002/dc-kash1/ior/bin/ior -vvv -b 128g -f /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/con.ior
Machine: Linux m5033
Start time skew across all tasks: 0.00 sec

Test 0 started: Mon Aug 10 16:20:31 2015
Path: /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS
FS: 2435.9 TiB   Used FS: 82.3%   Inodes: 1280.0 Mi   Used Inodes: 5.9%
Participating tasks: 2
Using reorderTasks '-C' (expecting block, not cyclic, task assignment)
Summary:
	api                = MPIIO (version=2, subversion=2)
	test filename      = /cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS/iorTest
	access             = file-per-process, independent
	pattern            = segmented (1 segment)
	ordering in a file = sequential offsets
	ordering inter file= constant task offsets = 1
	clients            = 2 (1 per node)
	repetitions        = 1
	xfersize           = 4 MiB
	blocksize          = 128 GiB
	aggregate filesize = 256 GiB

access    bw(MiB/s)  block(KiB) xfer(KiB)  open(s)    wr/rd(s)   close(s)   total(s)   iter
------    ---------  ---------- ---------  --------   --------   --------   --------   ----
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
write     2193.70    134217728  4096       0.012297   119.49     13.74      119.50     0   
delaying 10 seconds . . .

hints passed to MPI_File_open() {
}

hints returned from opened file {
	cb_buffer_size = 4194304
	romio_cb_read = automatic
	romio_cb_write = automatic
	cb_nodes = 1
	romio_no_indep_rw = false
	ind_rd_buffer_size = 4194304
	ind_wr_buffer_size = 524288
	romio_ds_read = automatic
	romio_ds_write = automatic
	cb_config_list = *:1
}
read      947.06     134217728  4096       0.016398   276.78     0.706449   276.80     0   
remove    -          -          -          -          -          -          0.025660   0   

Max Write: 2193.70 MiB/sec (2300.26 MB/sec)
Max Read:  947.06 MiB/sec (993.07 MB/sec)

Summary of all tests:
Operation   Max(MiB)   Min(MiB)  Mean(MiB)     StdDev    Mean(s) Test# #Tasks tPN reps fPP reord reordoff reordrand seed segcnt blksiz xsize aggsize API RefNum
write        2193.70    2193.70    2193.70       0.00  119.49851 0 2 1 1 1 1 1 0 0 1 137438953472 4194304 274877906944 MPIIO 0
read          947.06     947.06     947.06       0.00  276.79735 0 2 1 1 1 1 1 0 0 1 137438953472 4194304 274877906944 MPIIO 0

Finished: Mon Aug 10 16:27:28 2015
/cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS 

------------------------------------------------------------
Sender: LSF System <hpcadmin@m5033>
Subject: Job 497095: <NS_FPS_MPIIO> Done

Job <NS_FPS_MPIIO> was submitted from host <cosma-a> by user <dc-kash1> in cluster <cosma-p_cluster1>.
Job was executed on host(s) <1*m5033>, in queue <cosma5>, as user <dc-kash1> in cluster <cosma-p_cluster1>.
                            <1*m5039>
                            <1*m5379>
                            <1*m5380>
                            <1*m5381>
                            <1*m5382>
                            <1*m5383>
                            <1*m5385>
                            <1*m5386>
                            <1*m5393>
                            <1*m5394>
                            <1*m5396>
                            <1*m5402>
                            <1*m5405>
                            <1*m5406>
                            <1*m5407>
</cosma/home/dr002/dc-kash1> was used as the home directory.
</cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS> was used as the working directory.
Started at Mon Aug 10 16:13:43 2015
Results reported at Mon Aug 10 16:27:43 2015

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/tcsh

#BSUB -n 16
#BSUB -x
#BSUB -R "span[ptile=1]"
#BSUB -J NS_FPS_MPIIO
#BSUB -oo NS_FPS_MPIIO.out.%J
#BSUB -eo NS_FPS_MPIIO.err.%J
#BSUB -q cosma5
#BSUB -P dr002
#BSUB -W 08:00
 
  
set TARGET="/cosma5/data/dr002/dc-kash1/IOR_DiRAC_MPIIO/NS.FPS"
set IOR="/cosma5/data/dr002/dc-kash1/ior/bin/ior"
set IOR_SCRIPT="$TARGET/con.ior"


date '+%Y%m%d%H%M%S'

pushd $TARGET


setenv  LD_LIBRARY_PATH /cosma5/data/dr002/dc-kash1/hdf5-1.8.15-patch1/lib:$LD_LIBRARY_PATH
setenv  LD_RUN_PATH /cosma5/data/dr002/dc-kash1/hdf5-1.8.15-patch1/lib:$LD_RUN_PATH
setenv  LDFLAGS "-L/cosma5/data/dr002/dc-kash1/hdf5-1.8.15-patch1/lib"


setenv HDF5_DISABLE_VERSION_CHECK 1

set numNodes= ( 16 8 4 2 1 )
set blockSize=( 16 32 64 128 256 )

foreach test (`seq 5`)
    @ test=$test - 1
    set cmd="$IOR -vvv  -b ${blockSize[$test]}g -f $IOR_SCRIPT"
    mpirun -np ${numNodes[$test]}  $IOR -vvv  -b ${blockSize[$test]}g -f $IOR_SCRIPT
end
popd



------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time   :   1412.75 sec.
    Max Memory :       105 MB
    Max Swap   :       651 MB

    Max Processes  :        14
    Max Threads    :        14

The output (if any) is above this job summary.



PS:

Read file <NS_FPS_MPIIO.err.497095> for stderr output of this job.

